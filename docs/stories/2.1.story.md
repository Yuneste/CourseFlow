# Story 2.1: OpenAI Integration & File Analysis

## Status
Draft

## Story
**As a** developer,
**I want** to integrate OpenAI API to analyze and understand academic file content,
**so that** students can benefit from AI-powered file categorization, summaries, and study assistance

## Acceptance Criteria
1. OpenAI API key management in environment variables
2. Secure API route for file analysis
3. Extract text from PDFs, DOCX, PPTX
4. Send content to OpenAI for analysis
5. Rate limiting and error handling
6. Cost tracking per user
7. Graceful fallbacks for API failures

## Tasks / Subtasks
- [ ] Set up OpenAI client library and configuration (AC: 1, 2)
  - [ ] Install OpenAI SDK package
  - [ ] Create lib/openai/client.ts with proper initialization
  - [ ] Add OPENAI_API_KEY to environment variables and .env.example
  - [ ] Implement secure key management using lib/env.ts pattern
- [ ] Create file parsing utilities (AC: 3)
  - [ ] Create lib/parsers/pdf-parser.ts using pdf-parse or similar library
  - [ ] Create lib/parsers/docx-parser.ts using mammoth or similar
  - [ ] Create lib/parsers/pptx-parser.ts for PowerPoint files
  - [ ] Create lib/parsers/index.ts to export unified parsing interface
  - [ ] Add unit tests for each parser in __tests__/unit/lib/parsers/
- [ ] Implement AI file analyzer service (AC: 4, 7)
  - [ ] Create lib/ai/file-analyzer.ts with OpenAI integration
  - [ ] Design prompt templates for academic content analysis
  - [ ] Implement retry logic with exponential backoff
  - [ ] Add caching layer to minimize duplicate API calls
  - [ ] Create fallback mechanisms for API failures
- [ ] Create secure API endpoint for file analysis (AC: 2, 5)
  - [ ] Create app/api/ai/analyze/route.ts
  - [ ] Implement authentication check using withAuth middleware pattern
  - [ ] Add rate limiting specific to AI endpoints (20 requests/minute)
  - [ ] Validate file content before sending to OpenAI
  - [ ] Implement proper error responses with status codes
- [ ] Implement cost tracking system (AC: 6)
  - [ ] Create database migration for ai_usage_tracking table
  - [ ] Track tokens used per request in database
  - [ ] Associate costs with user_id and timestamp
  - [ ] Create lib/ai/cost-tracker.ts for usage monitoring
  - [ ] Add cost limits per user tier (use subscription limits pattern)
- [ ] Add comprehensive error handling (AC: 5, 7)
  - [ ] Implement circuit breaker pattern for OpenAI API
  - [ ] Create user-friendly error messages for common failures
  - [ ] Log errors to monitoring system (Sentry)
  - [ ] Ensure graceful degradation when AI is unavailable
- [ ] Create integration tests (Testing Requirements)
  - [ ] Test file upload → parsing → AI analysis flow
  - [ ] Test rate limiting and authentication
  - [ ] Test error scenarios and fallbacks
  - [ ] Test cost tracking accuracy

## Dev Notes

### Previous Story Insights
From Story 1.6 implementation:
- AI cost optimization already has foundation in lib/ai/cost-optimizer.ts
- Subscription tier limits pattern established in lib/subscriptions/tiers.ts
- Security patterns for API endpoints established in billing routes
[Source: Previous story 1.6 completion notes]

### Data Models
**File Model** - The primary model we'll be enhancing:
```typescript
interface File {
  id: string;
  user_id: string;
  course_id: string;
  original_name: string;
  display_name: string;
  storage_url: string;
  file_type: string;
  file_size: bigint;
  detected_language: string;
  ai_category: string;      // We'll populate this
  ai_summary: text;          // We'll populate this
  ai_summary_translations: jsonb;
  ai_confidence: float;      // We'll populate this
}
```
[Source: architecture/data-models.md#File]

### API Specifications
**New endpoint to create:**
- `POST /api/ai/analyze` - Analyze file content with OpenAI
  - Request body: `{ fileId: string, content: string, fileType: string }`
  - Response: `{ category: string, confidence: number, summary: string, language: string }`
  - Auth: Required (use withAuth middleware)
  - Rate limit: 20 requests/minute
[Source: architecture/backend-architecture.md#Function-Organization]

**OpenAI API Integration:**
- Base URL: https://api.openai.com/v1
- Endpoint: POST /chat/completions
- Auth: Bearer token (API key)
- Rate limit: 10,000 TPM for GPT-3.5-turbo
- Use streaming for long responses
[Source: architecture/external-apis.md#OpenAI-API]

### Component Specifications
No UI components in this story - backend only

### File Locations
Based on project structure:
- `lib/openai/client.ts` - OpenAI client configuration
- `lib/ai/file-analyzer.ts` - Main AI analysis logic
- `lib/ai/cost-tracker.ts` - Usage and cost tracking
- `lib/parsers/` - File parsing utilities
  - `pdf-parser.ts`
  - `docx-parser.ts`
  - `pptx-parser.ts`
  - `index.ts`
- `app/api/ai/analyze/route.ts` - API endpoint
[Source: architecture/unified-project-structure.md]

### Testing Requirements
- Test files location: `__tests__/unit/lib/ai/` and `__tests__/unit/api/ai/`
- Use Vitest framework (version 1.2+)
- Mock OpenAI API calls in tests
- Test authentication and rate limiting
- Include error scenario testing
[Source: architecture/testing-strategy.md#Test-Organization]

### Technical Constraints
- TypeScript 5.3+ for all code
- Use existing auth patterns from backend-architecture.md
- Follow error response format: `{ error: string }` with proper status codes
- Always validate environment variables through lib/env.ts
- Never access process.env directly
- All API routes must verify authentication before processing
[Source: architecture/coding-standards.md#Critical-Fullstack-Rules]

### Authentication Pattern
Use the existing withAuth middleware pattern:
```typescript
export const POST = withAuth(async (req, user) => {
  // Handler has access to authenticated user
});
```
[Source: architecture/backend-architecture.md#Middleware/Guards]

### Subscription Checking Pattern
For AI features that consume credits:
```typescript
export const POST = withSubscription('free', 'ai_analysis')(
  async (req, user, subscription) => {
    // Check and increment usage automatically
  }
);
```
[Source: architecture/backend-architecture.md#Subscription-check-middleware]

### Testing
**Test file locations:**
- Unit tests: `__tests__/unit/lib/ai/file-analyzer.test.ts`
- API tests: `__tests__/unit/api/ai/analyze.test.ts`
- Integration tests: `__tests__/integration/workflows/ai-analysis.test.ts`

**Testing requirements:**
- Use Vitest framework
- Mock external API calls (OpenAI)
- Test error scenarios and edge cases
- Verify rate limiting works correctly
- Test authentication and authorization
[Source: architecture/testing-strategy.md]

## Change Log
| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2024-01-XX | 1.0 | Initial story creation | Bob (SM) |

## Dev Agent Record
### Agent Model Used
(To be filled by dev agent)

### Debug Log References
(To be filled by dev agent)

### Completion Notes List
(To be filled by dev agent)

### File List
(To be filled by dev agent)

## QA Results
(To be filled by QA agent)